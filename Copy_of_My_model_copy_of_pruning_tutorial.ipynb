{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Copy of My model copy of pruning_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cinderallascent/LearnDeepLearning/blob/master/Copy_of_My_model_copy_of_pruning_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fL2HxW4IRAt"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4CRetTTIRAv"
      },
      "source": [
        "\n",
        "Pruning Simple Experiments\n",
        "=====================================\n",
        "**Author**: Brenda Zhuang_\n",
        "\n",
        "Basic steps: \n",
        "- Set up a simple example; \n",
        "- Use multiple pruning techniques;\n",
        "- Observe the behaviors from Pruned models\n",
        "\n",
        "Requirements\n",
        "------------\n",
        "``\"torch>=1.4.0a0+8e8a5e0\"``\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLpLIcc9IRAx"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrJabd6DIRAy"
      },
      "source": [
        "Create a model\n",
        "--------------\n",
        "\n",
        "To compare fairly, we will be using the MNIST model for the experiment. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9-mWfUUIRAy"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "model = Net().to(device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0BwsUviIRAz"
      },
      "source": [
        "Inspect a Module\n",
        "----------------\n",
        "\n",
        "Let's inspect the (unpruned) ``conv1`` layer in our Net model. It will contain two \n",
        "parameters ``weight`` and ``bias``, and no buffers, for now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4IsLFtbIRAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5903ca4-eda6-4d71-f1a5-849bfc458fac"
      },
      "source": [
        "module = model.conv1\n",
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight', Parameter containing:\n",
            "tensor([[[[ 0.0984,  0.0411,  0.1766,  0.1884, -0.0756],\n",
            "          [-0.1399,  0.0191, -0.0777,  0.1150, -0.1987],\n",
            "          [ 0.0259,  0.0334, -0.1127,  0.0060, -0.1902],\n",
            "          [-0.0800, -0.1647, -0.0032, -0.1455, -0.1311],\n",
            "          [-0.0138, -0.0432,  0.1030, -0.1955, -0.1549]]],\n",
            "\n",
            "\n",
            "        [[[-0.0998, -0.0203,  0.1126, -0.0524,  0.0367],\n",
            "          [-0.0032, -0.1609, -0.0224,  0.0229,  0.1291],\n",
            "          [-0.0191,  0.1257,  0.1793, -0.0510, -0.0719],\n",
            "          [ 0.0388, -0.1169,  0.1236,  0.0731, -0.0336],\n",
            "          [-0.0112, -0.1331, -0.0052,  0.1188,  0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1411,  0.0085,  0.1097, -0.0479, -0.1785],\n",
            "          [-0.0797, -0.0495, -0.1180, -0.1615,  0.0116],\n",
            "          [-0.1775,  0.0708,  0.1790, -0.1614,  0.0884],\n",
            "          [ 0.0317, -0.1074, -0.1253,  0.0006,  0.0160],\n",
            "          [-0.1220, -0.1230,  0.0395,  0.0125, -0.1751]]],\n",
            "\n",
            "\n",
            "        [[[-0.1686, -0.1602,  0.0640,  0.0196, -0.1771],\n",
            "          [-0.1681, -0.0297, -0.0537, -0.0480,  0.0987],\n",
            "          [ 0.1338, -0.1586,  0.0880,  0.1585,  0.1699],\n",
            "          [ 0.1357, -0.0387, -0.0941, -0.0602,  0.1939],\n",
            "          [ 0.1220, -0.1603, -0.0986, -0.0393, -0.0313]]],\n",
            "\n",
            "\n",
            "        [[[-0.1133, -0.1053, -0.0114,  0.1666,  0.1631],\n",
            "          [-0.1440, -0.1495,  0.1271,  0.1363, -0.0701],\n",
            "          [ 0.1714,  0.1525,  0.1687, -0.0815,  0.1522],\n",
            "          [ 0.0967, -0.0104, -0.0955, -0.0713, -0.1831],\n",
            "          [-0.0241,  0.0702,  0.1403,  0.0641, -0.1399]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0633, -0.1909, -0.0111, -0.0232, -0.1579],\n",
            "          [ 0.0659,  0.0259, -0.1342, -0.1412, -0.1739],\n",
            "          [ 0.0786,  0.1119, -0.1232,  0.1762,  0.0462],\n",
            "          [ 0.0900, -0.0295, -0.0603, -0.0081,  0.1578],\n",
            "          [ 0.1569,  0.0801, -0.0645,  0.1479, -0.1063]]],\n",
            "\n",
            "\n",
            "        [[[-0.1681,  0.1732, -0.1116, -0.1138, -0.0445],\n",
            "          [ 0.1615, -0.0428,  0.1822,  0.1980,  0.0129],\n",
            "          [-0.0620, -0.1677, -0.0618, -0.1749,  0.1052],\n",
            "          [ 0.1386, -0.1352,  0.0391,  0.0820, -0.0704],\n",
            "          [ 0.1616,  0.0238,  0.1882,  0.0308, -0.1999]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0705,  0.1388,  0.1899, -0.0169, -0.0172],\n",
            "          [ 0.0160,  0.0816, -0.0850,  0.1830, -0.1057],\n",
            "          [-0.0641, -0.0216, -0.0725,  0.0333,  0.0802],\n",
            "          [ 0.1104,  0.1061, -0.1603,  0.1832,  0.0924],\n",
            "          [-0.0556, -0.1438,  0.0023, -0.1136,  0.0646]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0822, -0.0548,  0.1086,  0.0608,  0.1248],\n",
            "          [-0.1032,  0.1795,  0.1195,  0.1821, -0.1689],\n",
            "          [ 0.0743,  0.1196,  0.0612,  0.1411, -0.0190],\n",
            "          [ 0.0282, -0.0203, -0.0523, -0.0639,  0.0532],\n",
            "          [ 0.0306,  0.1891, -0.0436, -0.1644, -0.1013]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047,  0.1715,  0.1962,  0.1461,  0.1267],\n",
            "          [-0.0324,  0.0106, -0.0890,  0.0509, -0.0528],\n",
            "          [ 0.1789, -0.1698,  0.0341,  0.1304,  0.0611],\n",
            "          [ 0.1210, -0.0284,  0.0389,  0.1786,  0.1030],\n",
            "          [ 0.0955,  0.0847, -0.1294, -0.1789, -0.0015]]]], requires_grad=True)), ('bias', Parameter containing:\n",
            "tensor([ 0.0856,  0.1389,  0.0977,  0.1143,  0.0870, -0.0845, -0.1945, -0.1372,\n",
            "         0.1183,  0.1799], requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFnBQpL9IRA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f103f304-da28-4021-9501-13b1b5d2ae0b"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CpBrZRWIRA1"
      },
      "source": [
        "Pruning a Module\n",
        "----------------\n",
        "\n",
        "To prune a module (in this example, the ``conv1`` layer of our Net \n",
        "architecture), first select a pruning technique among those available in \n",
        "``torch.nn.utils.prune`` (or\n",
        "`implement <#extending-torch-nn-utils-pruning-with-custom-pruning-functions>`_\n",
        "your own by subclassing \n",
        "``BasePruningMethod``). Then, specify the module and the name of the parameter to \n",
        "prune within that module. Finally, using the adequate keyword arguments \n",
        "required by the selected pruning technique, specify the pruning parameters.\n",
        "\n",
        "In this example, we will prune at random 30% of the connections in \n",
        "the parameter named ``weight`` in the ``conv1`` layer.\n",
        "The module is passed as the first argument to the function; ``name`` \n",
        "identifies the parameter within that module using its string identifier; and \n",
        "``amount`` indicates either the percentage of connections to prune (if it \n",
        "is a float between 0. and 1.), or the absolute number of connections to \n",
        "prune (if it is a non-negative integer).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8V86aPlIRA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d6879e-d7c1-494d-cb32-c3dcbbd420ef"
      },
      "source": [
        "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86-z9WtzIRA2"
      },
      "source": [
        "Pruning acts by removing ``weight`` from the parameters and replacing it with \n",
        "a new parameter called ``weight_orig`` (i.e. appending ``\"_orig\"`` to the \n",
        "initial parameter ``name``). ``weight_orig`` stores the unpruned version of \n",
        "the tensor. The ``bias`` was not pruned, so it will remain intact.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4GL88CJIRA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8058092a-0864-4324-ea50-6d4b4575cebd"
      },
      "source": [
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('bias', Parameter containing:\n",
            "tensor([ 0.0856,  0.1389,  0.0977,  0.1143,  0.0870, -0.0845, -0.1945, -0.1372,\n",
            "         0.1183,  0.1799], requires_grad=True)), ('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.0984,  0.0411,  0.1766,  0.1884, -0.0756],\n",
            "          [-0.1399,  0.0191, -0.0777,  0.1150, -0.1987],\n",
            "          [ 0.0259,  0.0334, -0.1127,  0.0060, -0.1902],\n",
            "          [-0.0800, -0.1647, -0.0032, -0.1455, -0.1311],\n",
            "          [-0.0138, -0.0432,  0.1030, -0.1955, -0.1549]]],\n",
            "\n",
            "\n",
            "        [[[-0.0998, -0.0203,  0.1126, -0.0524,  0.0367],\n",
            "          [-0.0032, -0.1609, -0.0224,  0.0229,  0.1291],\n",
            "          [-0.0191,  0.1257,  0.1793, -0.0510, -0.0719],\n",
            "          [ 0.0388, -0.1169,  0.1236,  0.0731, -0.0336],\n",
            "          [-0.0112, -0.1331, -0.0052,  0.1188,  0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1411,  0.0085,  0.1097, -0.0479, -0.1785],\n",
            "          [-0.0797, -0.0495, -0.1180, -0.1615,  0.0116],\n",
            "          [-0.1775,  0.0708,  0.1790, -0.1614,  0.0884],\n",
            "          [ 0.0317, -0.1074, -0.1253,  0.0006,  0.0160],\n",
            "          [-0.1220, -0.1230,  0.0395,  0.0125, -0.1751]]],\n",
            "\n",
            "\n",
            "        [[[-0.1686, -0.1602,  0.0640,  0.0196, -0.1771],\n",
            "          [-0.1681, -0.0297, -0.0537, -0.0480,  0.0987],\n",
            "          [ 0.1338, -0.1586,  0.0880,  0.1585,  0.1699],\n",
            "          [ 0.1357, -0.0387, -0.0941, -0.0602,  0.1939],\n",
            "          [ 0.1220, -0.1603, -0.0986, -0.0393, -0.0313]]],\n",
            "\n",
            "\n",
            "        [[[-0.1133, -0.1053, -0.0114,  0.1666,  0.1631],\n",
            "          [-0.1440, -0.1495,  0.1271,  0.1363, -0.0701],\n",
            "          [ 0.1714,  0.1525,  0.1687, -0.0815,  0.1522],\n",
            "          [ 0.0967, -0.0104, -0.0955, -0.0713, -0.1831],\n",
            "          [-0.0241,  0.0702,  0.1403,  0.0641, -0.1399]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0633, -0.1909, -0.0111, -0.0232, -0.1579],\n",
            "          [ 0.0659,  0.0259, -0.1342, -0.1412, -0.1739],\n",
            "          [ 0.0786,  0.1119, -0.1232,  0.1762,  0.0462],\n",
            "          [ 0.0900, -0.0295, -0.0603, -0.0081,  0.1578],\n",
            "          [ 0.1569,  0.0801, -0.0645,  0.1479, -0.1063]]],\n",
            "\n",
            "\n",
            "        [[[-0.1681,  0.1732, -0.1116, -0.1138, -0.0445],\n",
            "          [ 0.1615, -0.0428,  0.1822,  0.1980,  0.0129],\n",
            "          [-0.0620, -0.1677, -0.0618, -0.1749,  0.1052],\n",
            "          [ 0.1386, -0.1352,  0.0391,  0.0820, -0.0704],\n",
            "          [ 0.1616,  0.0238,  0.1882,  0.0308, -0.1999]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0705,  0.1388,  0.1899, -0.0169, -0.0172],\n",
            "          [ 0.0160,  0.0816, -0.0850,  0.1830, -0.1057],\n",
            "          [-0.0641, -0.0216, -0.0725,  0.0333,  0.0802],\n",
            "          [ 0.1104,  0.1061, -0.1603,  0.1832,  0.0924],\n",
            "          [-0.0556, -0.1438,  0.0023, -0.1136,  0.0646]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0822, -0.0548,  0.1086,  0.0608,  0.1248],\n",
            "          [-0.1032,  0.1795,  0.1195,  0.1821, -0.1689],\n",
            "          [ 0.0743,  0.1196,  0.0612,  0.1411, -0.0190],\n",
            "          [ 0.0282, -0.0203, -0.0523, -0.0639,  0.0532],\n",
            "          [ 0.0306,  0.1891, -0.0436, -0.1644, -0.1013]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047,  0.1715,  0.1962,  0.1461,  0.1267],\n",
            "          [-0.0324,  0.0106, -0.0890,  0.0509, -0.0528],\n",
            "          [ 0.1789, -0.1698,  0.0341,  0.1304,  0.0611],\n",
            "          [ 0.1210, -0.0284,  0.0389,  0.1786,  0.1030],\n",
            "          [ 0.0955,  0.0847, -0.1294, -0.1789, -0.0015]]]], requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgobVw7tIRA3"
      },
      "source": [
        "The pruning mask generated by the pruning technique selected above is saved \n",
        "as a module buffer named ``weight_mask`` (i.e. appending ``\"_mask\"`` to the \n",
        "initial parameter ``name``).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqiYIJOCIRA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c19b4cf-31bc-4a66-8409-9d76ed4fa46a"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight_mask', tensor([[[[0., 1., 1., 1., 0.],\n",
            "          [1., 1., 0., 0., 1.],\n",
            "          [0., 1., 1., 0., 1.],\n",
            "          [0., 0., 1., 0., 0.],\n",
            "          [0., 0., 1., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 1., 1., 1.],\n",
            "          [1., 0., 0., 0., 0.],\n",
            "          [0., 1., 0., 1., 0.],\n",
            "          [0., 1., 0., 0., 1.],\n",
            "          [1., 1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1., 0., 0.],\n",
            "          [1., 1., 1., 1., 1.],\n",
            "          [0., 1., 0., 1., 0.],\n",
            "          [0., 0., 1., 0., 0.],\n",
            "          [1., 1., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 0., 0.],\n",
            "          [0., 1., 1., 0., 1.],\n",
            "          [1., 0., 1., 0., 0.],\n",
            "          [1., 0., 1., 0., 0.],\n",
            "          [0., 0., 0., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 0., 0., 1.],\n",
            "          [0., 1., 0., 1., 1.],\n",
            "          [0., 1., 1., 0., 0.],\n",
            "          [0., 0., 0., 0., 1.],\n",
            "          [1., 1., 0., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1., 0., 1.],\n",
            "          [0., 1., 1., 1., 1.],\n",
            "          [0., 1., 1., 0., 0.],\n",
            "          [1., 1., 1., 0., 1.],\n",
            "          [0., 1., 0., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1., 1., 0.],\n",
            "          [0., 1., 1., 0., 0.],\n",
            "          [1., 0., 1., 0., 0.],\n",
            "          [1., 1., 1., 1., 0.],\n",
            "          [1., 1., 0., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 0., 1.],\n",
            "          [0., 0., 1., 1., 1.],\n",
            "          [1., 0., 0., 1., 0.],\n",
            "          [0., 1., 0., 0., 0.],\n",
            "          [1., 1., 1., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 1., 1., 1.],\n",
            "          [1., 0., 1., 1., 0.],\n",
            "          [1., 0., 1., 1., 1.],\n",
            "          [1., 0., 1., 0., 1.],\n",
            "          [0., 1., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 0., 0.],\n",
            "          [0., 0., 0., 1., 0.],\n",
            "          [0., 1., 0., 0., 1.],\n",
            "          [1., 1., 0., 0., 1.],\n",
            "          [1., 0., 0., 1., 1.]]]]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sziHajGIRA4"
      },
      "source": [
        "For the forward pass to work without modification, the ``weight`` attribute \n",
        "needs to exist. The pruning techniques implemented in \n",
        "``torch.nn.utils.prune`` compute the pruned version of the weight (by \n",
        "combining the mask with the original parameter) and store them in the \n",
        "attribute ``weight``. Note, this is no longer a parameter of the ``module``,\n",
        "it is now simply an attribute.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MJQxvIOIRA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6442ab-1042-46ac-a013-29e5e2d9428c"
      },
      "source": [
        "print(module.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.0000,  0.0411,  0.1766,  0.1884, -0.0000],\n",
            "          [-0.1399,  0.0191, -0.0000,  0.0000, -0.1987],\n",
            "          [ 0.0000,  0.0334, -0.1127,  0.0000, -0.1902],\n",
            "          [-0.0000, -0.0000, -0.0032, -0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000,  0.1030, -0.1955, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000,  0.1126, -0.0524,  0.0367],\n",
            "          [-0.0032, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.1257,  0.0000, -0.0510, -0.0000],\n",
            "          [ 0.0000, -0.1169,  0.0000,  0.0000, -0.0336],\n",
            "          [-0.0112, -0.1331, -0.0052,  0.1188,  0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0085,  0.1097, -0.0000, -0.0000],\n",
            "          [-0.0797, -0.0495, -0.1180, -0.1615,  0.0116],\n",
            "          [-0.0000,  0.0708,  0.0000, -0.1614,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.1253,  0.0000,  0.0000],\n",
            "          [-0.1220, -0.1230,  0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0297, -0.0537, -0.0000,  0.0987],\n",
            "          [ 0.1338, -0.0000,  0.0880,  0.0000,  0.0000],\n",
            "          [ 0.1357, -0.0000, -0.0941, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0393, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.1053, -0.0000,  0.0000,  0.1631],\n",
            "          [-0.0000, -0.1495,  0.0000,  0.1363, -0.0701],\n",
            "          [ 0.0000,  0.1525,  0.1687, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.1831],\n",
            "          [-0.0241,  0.0702,  0.0000,  0.0000, -0.1399]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.1909, -0.0111, -0.0000, -0.1579],\n",
            "          [ 0.0000,  0.0259, -0.1342, -0.1412, -0.1739],\n",
            "          [ 0.0000,  0.1119, -0.1232,  0.0000,  0.0000],\n",
            "          [ 0.0900, -0.0295, -0.0603, -0.0000,  0.1578],\n",
            "          [ 0.0000,  0.0801, -0.0000,  0.0000, -0.1063]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.1732, -0.1116, -0.1138, -0.0000],\n",
            "          [ 0.0000, -0.0428,  0.1822,  0.0000,  0.0000],\n",
            "          [-0.0620, -0.0000, -0.0618, -0.0000,  0.0000],\n",
            "          [ 0.1386, -0.1352,  0.0391,  0.0820, -0.0000],\n",
            "          [ 0.1616,  0.0238,  0.0000,  0.0308, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000, -0.0000, -0.0172],\n",
            "          [ 0.0000,  0.0000, -0.0850,  0.1830, -0.1057],\n",
            "          [-0.0641, -0.0000, -0.0000,  0.0333,  0.0000],\n",
            "          [ 0.0000,  0.1061, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0556, -0.1438,  0.0023, -0.0000,  0.0646]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0822, -0.0000,  0.1086,  0.0608,  0.1248],\n",
            "          [-0.1032,  0.0000,  0.1195,  0.1821, -0.0000],\n",
            "          [ 0.0743,  0.0000,  0.0612,  0.1411, -0.0190],\n",
            "          [ 0.0282, -0.0000, -0.0523, -0.0000,  0.0532],\n",
            "          [ 0.0000,  0.1891, -0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047,  0.1715,  0.1962,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000,  0.0509, -0.0000],\n",
            "          [ 0.0000, -0.1698,  0.0000,  0.0000,  0.0611],\n",
            "          [ 0.1210, -0.0284,  0.0000,  0.0000,  0.1030],\n",
            "          [ 0.0955,  0.0000, -0.0000, -0.1789, -0.0015]]]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbKW3W30IRA4"
      },
      "source": [
        "Finally, pruning is applied prior to each forward pass using PyTorch's\n",
        "``forward_pre_hooks``. Specifically, when the ``module`` is pruned, as we \n",
        "have done here, it will acquire a ``forward_pre_hook`` for each parameter \n",
        "associated with it that gets pruned. In this case, since we have so far \n",
        "only pruned the original parameter named ``weight``, only one hook will be\n",
        "present.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j5uq_80IRA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8b771b-c4dc-4ba1-952a-b6075b91a1e5"
      },
      "source": [
        "print(module._forward_pre_hooks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([(1, <torch.nn.utils.prune.PruningContainer object at 0x7fc9bd29acd0>)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9IHKef3IRA5"
      },
      "source": [
        "For completeness, we can now prune the ``bias`` too, to see how the \n",
        "parameters, buffers, hooks, and attributes of the ``module`` change.\n",
        "Just for the sake of trying out another pruning technique, here we prune the \n",
        "3 smallest entries in the bias by L1 norm, as implemented in the \n",
        "``l1_unstructured`` pruning function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmgXSN1IIRA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc60e42d-21e3-48d0-f4d5-127ba721509e"
      },
      "source": [
        "prune.l1_unstructured(module, name=\"bias\", amount=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0TzedGTIRA5"
      },
      "source": [
        "We now expect the named parameters to include both ``weight_orig`` (from \n",
        "before) and ``bias_orig``. The buffers will include ``weight_mask`` and \n",
        "``bias_mask``. The pruned versions of the two tensors will exist as \n",
        "module attributes, and the module will now have two ``forward_pre_hooks``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLV2ge0qIRA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26fe19c8-bb2c-4b48-e7c7-c2e34a8c67f8"
      },
      "source": [
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.0984,  0.0411,  0.1766,  0.1884, -0.0756],\n",
            "          [-0.1399,  0.0191, -0.0777,  0.1150, -0.1987],\n",
            "          [ 0.0259,  0.0334, -0.1127,  0.0060, -0.1902],\n",
            "          [-0.0800, -0.1647, -0.0032, -0.1455, -0.1311],\n",
            "          [-0.0138, -0.0432,  0.1030, -0.1955, -0.1549]]],\n",
            "\n",
            "\n",
            "        [[[-0.0998, -0.0203,  0.1126, -0.0524,  0.0367],\n",
            "          [-0.0032, -0.1609, -0.0224,  0.0229,  0.1291],\n",
            "          [-0.0191,  0.1257,  0.1793, -0.0510, -0.0719],\n",
            "          [ 0.0388, -0.1169,  0.1236,  0.0731, -0.0336],\n",
            "          [-0.0112, -0.1331, -0.0052,  0.1188,  0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1411,  0.0085,  0.1097, -0.0479, -0.1785],\n",
            "          [-0.0797, -0.0495, -0.1180, -0.1615,  0.0116],\n",
            "          [-0.1775,  0.0708,  0.1790, -0.1614,  0.0884],\n",
            "          [ 0.0317, -0.1074, -0.1253,  0.0006,  0.0160],\n",
            "          [-0.1220, -0.1230,  0.0395,  0.0125, -0.1751]]],\n",
            "\n",
            "\n",
            "        [[[-0.1686, -0.1602,  0.0640,  0.0196, -0.1771],\n",
            "          [-0.1681, -0.0297, -0.0537, -0.0480,  0.0987],\n",
            "          [ 0.1338, -0.1586,  0.0880,  0.1585,  0.1699],\n",
            "          [ 0.1357, -0.0387, -0.0941, -0.0602,  0.1939],\n",
            "          [ 0.1220, -0.1603, -0.0986, -0.0393, -0.0313]]],\n",
            "\n",
            "\n",
            "        [[[-0.1133, -0.1053, -0.0114,  0.1666,  0.1631],\n",
            "          [-0.1440, -0.1495,  0.1271,  0.1363, -0.0701],\n",
            "          [ 0.1714,  0.1525,  0.1687, -0.0815,  0.1522],\n",
            "          [ 0.0967, -0.0104, -0.0955, -0.0713, -0.1831],\n",
            "          [-0.0241,  0.0702,  0.1403,  0.0641, -0.1399]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0633, -0.1909, -0.0111, -0.0232, -0.1579],\n",
            "          [ 0.0659,  0.0259, -0.1342, -0.1412, -0.1739],\n",
            "          [ 0.0786,  0.1119, -0.1232,  0.1762,  0.0462],\n",
            "          [ 0.0900, -0.0295, -0.0603, -0.0081,  0.1578],\n",
            "          [ 0.1569,  0.0801, -0.0645,  0.1479, -0.1063]]],\n",
            "\n",
            "\n",
            "        [[[-0.1681,  0.1732, -0.1116, -0.1138, -0.0445],\n",
            "          [ 0.1615, -0.0428,  0.1822,  0.1980,  0.0129],\n",
            "          [-0.0620, -0.1677, -0.0618, -0.1749,  0.1052],\n",
            "          [ 0.1386, -0.1352,  0.0391,  0.0820, -0.0704],\n",
            "          [ 0.1616,  0.0238,  0.1882,  0.0308, -0.1999]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0705,  0.1388,  0.1899, -0.0169, -0.0172],\n",
            "          [ 0.0160,  0.0816, -0.0850,  0.1830, -0.1057],\n",
            "          [-0.0641, -0.0216, -0.0725,  0.0333,  0.0802],\n",
            "          [ 0.1104,  0.1061, -0.1603,  0.1832,  0.0924],\n",
            "          [-0.0556, -0.1438,  0.0023, -0.1136,  0.0646]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0822, -0.0548,  0.1086,  0.0608,  0.1248],\n",
            "          [-0.1032,  0.1795,  0.1195,  0.1821, -0.1689],\n",
            "          [ 0.0743,  0.1196,  0.0612,  0.1411, -0.0190],\n",
            "          [ 0.0282, -0.0203, -0.0523, -0.0639,  0.0532],\n",
            "          [ 0.0306,  0.1891, -0.0436, -0.1644, -0.1013]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047,  0.1715,  0.1962,  0.1461,  0.1267],\n",
            "          [-0.0324,  0.0106, -0.0890,  0.0509, -0.0528],\n",
            "          [ 0.1789, -0.1698,  0.0341,  0.1304,  0.0611],\n",
            "          [ 0.1210, -0.0284,  0.0389,  0.1786,  0.1030],\n",
            "          [ 0.0955,  0.0847, -0.1294, -0.1789, -0.0015]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
            "tensor([ 0.0856,  0.1389,  0.0977,  0.1143,  0.0870, -0.0845, -0.1945, -0.1372,\n",
            "         0.1183,  0.1799], requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NOND7DTIRA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f84daa9-25a7-451d-da4d-311373556ab0"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight_mask', tensor([[[[0., 1., 1., 1., 0.],\n",
            "          [1., 1., 0., 0., 1.],\n",
            "          [0., 1., 1., 0., 1.],\n",
            "          [0., 0., 1., 0., 0.],\n",
            "          [0., 0., 1., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 1., 1., 1.],\n",
            "          [1., 0., 0., 0., 0.],\n",
            "          [0., 1., 0., 1., 0.],\n",
            "          [0., 1., 0., 0., 1.],\n",
            "          [1., 1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1., 0., 0.],\n",
            "          [1., 1., 1., 1., 1.],\n",
            "          [0., 1., 0., 1., 0.],\n",
            "          [0., 0., 1., 0., 0.],\n",
            "          [1., 1., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 0., 0.],\n",
            "          [0., 1., 1., 0., 1.],\n",
            "          [1., 0., 1., 0., 0.],\n",
            "          [1., 0., 1., 0., 0.],\n",
            "          [0., 0., 0., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 0., 0., 1.],\n",
            "          [0., 1., 0., 1., 1.],\n",
            "          [0., 1., 1., 0., 0.],\n",
            "          [0., 0., 0., 0., 1.],\n",
            "          [1., 1., 0., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1., 0., 1.],\n",
            "          [0., 1., 1., 1., 1.],\n",
            "          [0., 1., 1., 0., 0.],\n",
            "          [1., 1., 1., 0., 1.],\n",
            "          [0., 1., 0., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1., 1., 0.],\n",
            "          [0., 1., 1., 0., 0.],\n",
            "          [1., 0., 1., 0., 0.],\n",
            "          [1., 1., 1., 1., 0.],\n",
            "          [1., 1., 0., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 0., 1.],\n",
            "          [0., 0., 1., 1., 1.],\n",
            "          [1., 0., 0., 1., 0.],\n",
            "          [0., 1., 0., 0., 0.],\n",
            "          [1., 1., 1., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 1., 1., 1.],\n",
            "          [1., 0., 1., 1., 0.],\n",
            "          [1., 0., 1., 1., 1.],\n",
            "          [1., 0., 1., 0., 1.],\n",
            "          [0., 1., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 0., 0.],\n",
            "          [0., 0., 0., 1., 0.],\n",
            "          [0., 1., 0., 0., 1.],\n",
            "          [1., 1., 0., 0., 1.],\n",
            "          [1., 0., 0., 1., 1.]]]])), ('bias_mask', tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 1.]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58nKWpk-IRA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a793583-cc36-4462-9094-3fcb5238d3a3"
      },
      "source": [
        "print(module.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0000,  0.1389,  0.0977,  0.1143,  0.0000, -0.0000, -0.1945, -0.1372,\n",
            "         0.1183,  0.1799], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuDxap88IRA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09af1a1b-71d8-45f9-b322-6e7c0c7d2e85"
      },
      "source": [
        "print(module._forward_pre_hooks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([(1, <torch.nn.utils.prune.PruningContainer object at 0x7fc9bd29acd0>), (2, <torch.nn.utils.prune.L1Unstructured object at 0x7fc9bd22a0d0>)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7YqdEuDIRA6"
      },
      "source": [
        "Iterative Pruning\n",
        "-----------------\n",
        "\n",
        "The same parameter in a module can be pruned multiple times, with the \n",
        "effect of the various pruning calls being equal to the combination of the\n",
        "various masks applied in series.\n",
        "The combination of a new mask with the old mask is handled by the \n",
        "``PruningContainer``'s ``compute_mask`` method.\n",
        "\n",
        "Say, for example, that we now want to further prune ``module.weight``, this\n",
        "time using structured pruning along the 0th axis of the tensor (the 0th axis \n",
        "corresponds to the output channels of the convolutional layer and has \n",
        "dimensionality 6 for ``conv1``), based on the channels' L2 norm. This can be \n",
        "achieved using the ``ln_structured`` function, with ``n=2`` and ``dim=0``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOQk6N3aIRA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5d16b5-1134-4e01-b708-aa4b6e34ea36"
      },
      "source": [
        "prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n",
        "\n",
        "# As we can verify, this will zero out all the connections corresponding to \n",
        "# 50% (3 out of 6) of the channels, while preserving the action of the \n",
        "# previous mask.\n",
        "print(module.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.0000,  0.0411,  0.1766,  0.1884, -0.0000],\n",
            "          [-0.1399,  0.0191, -0.0000,  0.0000, -0.1987],\n",
            "          [ 0.0000,  0.0334, -0.1127,  0.0000, -0.1902],\n",
            "          [-0.0000, -0.0000, -0.0032, -0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000,  0.1030, -0.1955, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.1053, -0.0000,  0.0000,  0.1631],\n",
            "          [-0.0000, -0.1495,  0.0000,  0.1363, -0.0701],\n",
            "          [ 0.0000,  0.1525,  0.1687, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.1831],\n",
            "          [-0.0241,  0.0702,  0.0000,  0.0000, -0.1399]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.1909, -0.0111, -0.0000, -0.1579],\n",
            "          [ 0.0000,  0.0259, -0.1342, -0.1412, -0.1739],\n",
            "          [ 0.0000,  0.1119, -0.1232,  0.0000,  0.0000],\n",
            "          [ 0.0900, -0.0295, -0.0603, -0.0000,  0.1578],\n",
            "          [ 0.0000,  0.0801, -0.0000,  0.0000, -0.1063]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.1732, -0.1116, -0.1138, -0.0000],\n",
            "          [ 0.0000, -0.0428,  0.1822,  0.0000,  0.0000],\n",
            "          [-0.0620, -0.0000, -0.0618, -0.0000,  0.0000],\n",
            "          [ 0.1386, -0.1352,  0.0391,  0.0820, -0.0000],\n",
            "          [ 0.1616,  0.0238,  0.0000,  0.0308, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047,  0.1715,  0.1962,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000,  0.0509, -0.0000],\n",
            "          [ 0.0000, -0.1698,  0.0000,  0.0000,  0.0611],\n",
            "          [ 0.1210, -0.0284,  0.0000,  0.0000,  0.1030],\n",
            "          [ 0.0955,  0.0000, -0.0000, -0.1789, -0.0015]]]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYAFss0lIRA6"
      },
      "source": [
        "The corresponding hook will now be of type \n",
        "``torch.nn.utils.prune.PruningContainer``, and will store the history of \n",
        "pruning applied to the ``weight`` parameter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a82evW_AIRA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee059f3-c3af-4a6f-f932-bc29ab64a402"
      },
      "source": [
        "for hook in module._forward_pre_hooks.values():\n",
        "    if hook._tensor_name == \"weight\":  # select out the correct hook\n",
        "        break\n",
        "\n",
        "print(list(hook))  # pruning history in the container"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<torch.nn.utils.prune.RandomUnstructured object at 0x7fca191ed210>, <torch.nn.utils.prune.RandomUnstructured object at 0x7fc9bd29aad0>, <torch.nn.utils.prune.LnStructured object at 0x7fc9bd29af50>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqID3J2IIRA7"
      },
      "source": [
        "Serializing a pruned model\n",
        "--------------------------\n",
        "All relevant tensors, including the mask buffers and the original parameters\n",
        "used to compute the pruned tensors are stored in the model's ``state_dict`` \n",
        "and can therefore be easily serialized and saved, if needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPJpPUXAIRA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3066f15e-8eb9-4d13-f8b9-c947c98a6261"
      },
      "source": [
        "print(model.state_dict().keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9x62Tl5IRA7"
      },
      "source": [
        "Remove pruning re-parametrization\n",
        "---------------------------------\n",
        "\n",
        "To make the pruning permanent, remove the re-parametrization in terms\n",
        "of ``weight_orig`` and ``weight_mask``, and remove the ``forward_pre_hook``,\n",
        "we can use the ``remove`` functionality from ``torch.nn.utils.prune``.\n",
        "Note that this doesn't undo the pruning, as if it never happened. It simply \n",
        "makes it permanent, instead, by reassigning the parameter ``weight`` to the \n",
        "model parameters, in its pruned version.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0sRRP2MIRA7"
      },
      "source": [
        "Prior to removing the re-parametrization:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPE1oBTJIRA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abfccbc2-8521-4d93-96b7-23b1bff13237"
      },
      "source": [
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.0984,  0.0411,  0.1766,  0.1884, -0.0756],\n",
            "          [-0.1399,  0.0191, -0.0777,  0.1150, -0.1987],\n",
            "          [ 0.0259,  0.0334, -0.1127,  0.0060, -0.1902],\n",
            "          [-0.0800, -0.1647, -0.0032, -0.1455, -0.1311],\n",
            "          [-0.0138, -0.0432,  0.1030, -0.1955, -0.1549]]],\n",
            "\n",
            "\n",
            "        [[[-0.0998, -0.0203,  0.1126, -0.0524,  0.0367],\n",
            "          [-0.0032, -0.1609, -0.0224,  0.0229,  0.1291],\n",
            "          [-0.0191,  0.1257,  0.1793, -0.0510, -0.0719],\n",
            "          [ 0.0388, -0.1169,  0.1236,  0.0731, -0.0336],\n",
            "          [-0.0112, -0.1331, -0.0052,  0.1188,  0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1411,  0.0085,  0.1097, -0.0479, -0.1785],\n",
            "          [-0.0797, -0.0495, -0.1180, -0.1615,  0.0116],\n",
            "          [-0.1775,  0.0708,  0.1790, -0.1614,  0.0884],\n",
            "          [ 0.0317, -0.1074, -0.1253,  0.0006,  0.0160],\n",
            "          [-0.1220, -0.1230,  0.0395,  0.0125, -0.1751]]],\n",
            "\n",
            "\n",
            "        [[[-0.1686, -0.1602,  0.0640,  0.0196, -0.1771],\n",
            "          [-0.1681, -0.0297, -0.0537, -0.0480,  0.0987],\n",
            "          [ 0.1338, -0.1586,  0.0880,  0.1585,  0.1699],\n",
            "          [ 0.1357, -0.0387, -0.0941, -0.0602,  0.1939],\n",
            "          [ 0.1220, -0.1603, -0.0986, -0.0393, -0.0313]]],\n",
            "\n",
            "\n",
            "        [[[-0.1133, -0.1053, -0.0114,  0.1666,  0.1631],\n",
            "          [-0.1440, -0.1495,  0.1271,  0.1363, -0.0701],\n",
            "          [ 0.1714,  0.1525,  0.1687, -0.0815,  0.1522],\n",
            "          [ 0.0967, -0.0104, -0.0955, -0.0713, -0.1831],\n",
            "          [-0.0241,  0.0702,  0.1403,  0.0641, -0.1399]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0633, -0.1909, -0.0111, -0.0232, -0.1579],\n",
            "          [ 0.0659,  0.0259, -0.1342, -0.1412, -0.1739],\n",
            "          [ 0.0786,  0.1119, -0.1232,  0.1762,  0.0462],\n",
            "          [ 0.0900, -0.0295, -0.0603, -0.0081,  0.1578],\n",
            "          [ 0.1569,  0.0801, -0.0645,  0.1479, -0.1063]]],\n",
            "\n",
            "\n",
            "        [[[-0.1681,  0.1732, -0.1116, -0.1138, -0.0445],\n",
            "          [ 0.1615, -0.0428,  0.1822,  0.1980,  0.0129],\n",
            "          [-0.0620, -0.1677, -0.0618, -0.1749,  0.1052],\n",
            "          [ 0.1386, -0.1352,  0.0391,  0.0820, -0.0704],\n",
            "          [ 0.1616,  0.0238,  0.1882,  0.0308, -0.1999]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0705,  0.1388,  0.1899, -0.0169, -0.0172],\n",
            "          [ 0.0160,  0.0816, -0.0850,  0.1830, -0.1057],\n",
            "          [-0.0641, -0.0216, -0.0725,  0.0333,  0.0802],\n",
            "          [ 0.1104,  0.1061, -0.1603,  0.1832,  0.0924],\n",
            "          [-0.0556, -0.1438,  0.0023, -0.1136,  0.0646]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0822, -0.0548,  0.1086,  0.0608,  0.1248],\n",
            "          [-0.1032,  0.1795,  0.1195,  0.1821, -0.1689],\n",
            "          [ 0.0743,  0.1196,  0.0612,  0.1411, -0.0190],\n",
            "          [ 0.0282, -0.0203, -0.0523, -0.0639,  0.0532],\n",
            "          [ 0.0306,  0.1891, -0.0436, -0.1644, -0.1013]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047,  0.1715,  0.1962,  0.1461,  0.1267],\n",
            "          [-0.0324,  0.0106, -0.0890,  0.0509, -0.0528],\n",
            "          [ 0.1789, -0.1698,  0.0341,  0.1304,  0.0611],\n",
            "          [ 0.1210, -0.0284,  0.0389,  0.1786,  0.1030],\n",
            "          [ 0.0955,  0.0847, -0.1294, -0.1789, -0.0015]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
            "tensor([ 0.0856,  0.1389,  0.0977,  0.1143,  0.0870, -0.0845, -0.1945, -0.1372,\n",
            "         0.1183,  0.1799], requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51JmukoUIRA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5462a741-d993-4a5d-c89f-f67b21128dbb"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight_mask', tensor([[[[0., 1., 1., 1., 0.],\n",
            "          [1., 1., 0., 0., 1.],\n",
            "          [0., 1., 1., 0., 1.],\n",
            "          [0., 0., 1., 0., 0.],\n",
            "          [0., 0., 1., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 0., 0., 1.],\n",
            "          [0., 1., 0., 1., 1.],\n",
            "          [0., 1., 1., 0., 0.],\n",
            "          [0., 0., 0., 0., 1.],\n",
            "          [1., 1., 0., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1., 0., 1.],\n",
            "          [0., 1., 1., 1., 1.],\n",
            "          [0., 1., 1., 0., 0.],\n",
            "          [1., 1., 1., 0., 1.],\n",
            "          [0., 1., 0., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1., 1., 0.],\n",
            "          [0., 1., 1., 0., 0.],\n",
            "          [1., 0., 1., 0., 0.],\n",
            "          [1., 1., 1., 1., 0.],\n",
            "          [1., 1., 0., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 0., 0.],\n",
            "          [0., 0., 0., 1., 0.],\n",
            "          [0., 1., 0., 0., 1.],\n",
            "          [1., 1., 0., 0., 1.],\n",
            "          [1., 0., 0., 1., 1.]]]])), ('bias_mask', tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 1.]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWyT-k-LIRA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c23acbe-f66b-4362-ef43-6d48f86acf1b"
      },
      "source": [
        "print(module.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.0000,  0.0411,  0.1766,  0.1884, -0.0000],\n",
            "          [-0.1399,  0.0191, -0.0000,  0.0000, -0.1987],\n",
            "          [ 0.0000,  0.0334, -0.1127,  0.0000, -0.1902],\n",
            "          [-0.0000, -0.0000, -0.0032, -0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000,  0.1030, -0.1955, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.1053, -0.0000,  0.0000,  0.1631],\n",
            "          [-0.0000, -0.1495,  0.0000,  0.1363, -0.0701],\n",
            "          [ 0.0000,  0.1525,  0.1687, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.1831],\n",
            "          [-0.0241,  0.0702,  0.0000,  0.0000, -0.1399]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.1909, -0.0111, -0.0000, -0.1579],\n",
            "          [ 0.0000,  0.0259, -0.1342, -0.1412, -0.1739],\n",
            "          [ 0.0000,  0.1119, -0.1232,  0.0000,  0.0000],\n",
            "          [ 0.0900, -0.0295, -0.0603, -0.0000,  0.1578],\n",
            "          [ 0.0000,  0.0801, -0.0000,  0.0000, -0.1063]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.1732, -0.1116, -0.1138, -0.0000],\n",
            "          [ 0.0000, -0.0428,  0.1822,  0.0000,  0.0000],\n",
            "          [-0.0620, -0.0000, -0.0618, -0.0000,  0.0000],\n",
            "          [ 0.1386, -0.1352,  0.0391,  0.0820, -0.0000],\n",
            "          [ 0.1616,  0.0238,  0.0000,  0.0308, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047,  0.1715,  0.1962,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000,  0.0509, -0.0000],\n",
            "          [ 0.0000, -0.1698,  0.0000,  0.0000,  0.0611],\n",
            "          [ 0.1210, -0.0284,  0.0000,  0.0000,  0.1030],\n",
            "          [ 0.0955,  0.0000, -0.0000, -0.1789, -0.0015]]]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATV0cq2EIRA8"
      },
      "source": [
        "After removing the re-parametrization:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LnTwV87IRA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80666192-169e-4fff-cc9d-90e0e45e0c19"
      },
      "source": [
        "prune.remove(module, 'weight')\n",
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('bias_orig', Parameter containing:\n",
            "tensor([ 0.0856,  0.1389,  0.0977,  0.1143,  0.0870, -0.0845, -0.1945, -0.1372,\n",
            "         0.1183,  0.1799], requires_grad=True)), ('weight', Parameter containing:\n",
            "tensor([[[[ 0.0000,  0.0411,  0.1766,  0.1884, -0.0000],\n",
            "          [-0.1399,  0.0191, -0.0000,  0.0000, -0.1987],\n",
            "          [ 0.0000,  0.0334, -0.1127,  0.0000, -0.1902],\n",
            "          [-0.0000, -0.0000, -0.0032, -0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000,  0.1030, -0.1955, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000, -0.1053, -0.0000,  0.0000,  0.1631],\n",
            "          [-0.0000, -0.1495,  0.0000,  0.1363, -0.0701],\n",
            "          [ 0.0000,  0.1525,  0.1687, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.1831],\n",
            "          [-0.0241,  0.0702,  0.0000,  0.0000, -0.1399]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.1909, -0.0111, -0.0000, -0.1579],\n",
            "          [ 0.0000,  0.0259, -0.1342, -0.1412, -0.1739],\n",
            "          [ 0.0000,  0.1119, -0.1232,  0.0000,  0.0000],\n",
            "          [ 0.0900, -0.0295, -0.0603, -0.0000,  0.1578],\n",
            "          [ 0.0000,  0.0801, -0.0000,  0.0000, -0.1063]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.1732, -0.1116, -0.1138, -0.0000],\n",
            "          [ 0.0000, -0.0428,  0.1822,  0.0000,  0.0000],\n",
            "          [-0.0620, -0.0000, -0.0618, -0.0000,  0.0000],\n",
            "          [ 0.1386, -0.1352,  0.0391,  0.0820, -0.0000],\n",
            "          [ 0.1616,  0.0238,  0.0000,  0.0308, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047,  0.1715,  0.1962,  0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000,  0.0509, -0.0000],\n",
            "          [ 0.0000, -0.1698,  0.0000,  0.0000,  0.0611],\n",
            "          [ 0.1210, -0.0284,  0.0000,  0.0000,  0.1030],\n",
            "          [ 0.0955,  0.0000, -0.0000, -0.1789, -0.0015]]]], requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5tNJJZVIRA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891ffd91-55da-48a2-ab22-9adad6e19705"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('bias_mask', tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 1.]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4e8QtH0IRA8"
      },
      "source": [
        "Pruning multiple parameters in a model \n",
        "--------------------------------------\n",
        "\n",
        "By specifying the desired pruning technique and parameters, we can easily \n",
        "prune multiple tensors in a network, perhaps according to their type, as we \n",
        "will see in this example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hJZknc8O2Zi"
      },
      "source": [
        "import torchvision\n",
        "batch_size_test = 1000\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)\n",
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.shape\n",
        "test_losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCV0-qRaIRA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127be11d-f858-4cb4-deae-6bb5b3d8b621"
      },
      "source": [
        "new_model = Net()\n",
        "for name, module in new_model.named_modules():\n",
        "    # prune 20% of connections in all 2D-conv layers \n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.4)\n",
        "    # prune 40% of connections in all linear layers \n",
        "    elif isinstance(module, torch.nn.Linear):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.1)\n",
        "\n",
        "print(dict(new_model.named_buffers()).keys())  # to verify that all masks exist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72forwgCP9qY"
      },
      "source": [
        "def test():\n",
        "  new_model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      output = new_model(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_losses.append(test_loss)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W0euGV2QBf7",
        "outputId": "3aafd4fe-323e-4802-b70c-fe107811240e"
      },
      "source": [
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.2964, Accuracy: 1383/10000 (14%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDWQKIdaIRA8"
      },
      "source": [
        "Global pruning\n",
        "--------------\n",
        "\n",
        "So far, we only looked at what is usually referred to as \"local\" pruning,\n",
        "i.e. the practice of pruning tensors in a model one by one, by \n",
        "comparing the statistics (weight magnitude, activation, gradient, etc.) of \n",
        "each entry exclusively to the other entries in that tensor. However, a \n",
        "common and perhaps more powerful technique is to prune the model all at \n",
        "once, by removing (for example) the lowest 20% of connections across the \n",
        "whole model, instead of removing the lowest 20% of connections in each \n",
        "layer. This is likely to result in different pruning percentages per layer.\n",
        "Let's see how to do that using ``global_unstructured`` from \n",
        "``torch.nn.utils.prune``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAQNcZhqIRA8"
      },
      "source": [
        "model = Net()\n",
        "\n",
        "parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        ")\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqCUVwiZIRA9"
      },
      "source": [
        "Now we can check the sparsity induced in every pruned parameter, which will \n",
        "not be equal to 20% in each layer. However, the global sparsity will be \n",
        "(approximately) 20%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXP_AxJOIRA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d69c57-86ad-471c-9a37-0411394b1ede"
      },
      "source": [
        "print(\n",
        "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.conv1.weight == 0))\n",
        "        / float(model.conv1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.conv2.weight == 0))\n",
        "        / float(model.conv2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc1.weight == 0))\n",
        "        / float(model.fc1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc2.weight == 0))\n",
        "        / float(model.fc2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Global sparsity: {:.2f}%\".format(\n",
        "        100. * float(\n",
        "            torch.sum(model.conv1.weight == 0)\n",
        "            + torch.sum(model.conv2.weight == 0)\n",
        "            + torch.sum(model.fc1.weight == 0)\n",
        "            + torch.sum(model.fc2.weight == 0)\n",
        "        )\n",
        "        / float(\n",
        "            model.conv1.weight.nelement()\n",
        "            + model.conv2.weight.nelement()\n",
        "            + model.fc1.weight.nelement()\n",
        "            + model.fc2.weight.nelement()\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in conv1.weight: 6.40%\n",
            "Sparsity in conv2.weight: 17.82%\n",
            "Sparsity in fc1.weight: 21.31%\n",
            "Sparsity in fc2.weight: 6.80%\n",
            "Global sparsity: 20.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzJT1K1ARE-e",
        "outputId": "404cd4e3-4d4a-4ebf-d6c7-4b9cde77f1ec"
      },
      "source": [
        "new_model = model\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3090, Accuracy: 931/10000 (9%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1HioeWjIRA9"
      },
      "source": [
        "Extending ``torch.nn.utils.prune`` with custom pruning functions\n",
        "------------------------------------------------------------------\n",
        "To implement your own pruning function, you can extend the\n",
        "``nn.utils.prune`` module by subclassing the ``BasePruningMethod``\n",
        "base class, the same way all other pruning methods do. The base class\n",
        "implements the following methods for you: ``__call__``, ``apply_mask``,\n",
        "``apply``, ``prune``, and ``remove``. Beyond some special cases, you shouldn't\n",
        "have to reimplement these methods for your new pruning technique.\n",
        "You will, however, have to implement ``__init__`` (the constructor),\n",
        "and ``compute_mask`` (the instructions on how to compute the mask\n",
        "for the given tensor according to the logic of your pruning\n",
        "technique). In addition, you will have to specify which type of\n",
        "pruning this technique implements (supported options are ``global``,\n",
        "``structured``, and ``unstructured``). This is needed to determine\n",
        "how to combine masks in the case in which pruning is applied\n",
        "iteratively. In other words, when pruning a pre-pruned parameter,\n",
        "the current prunining techique is expected to act on the unpruned\n",
        "portion of the parameter. Specifying the ``PRUNING_TYPE`` will\n",
        "enable the ``PruningContainer`` (which handles the iterative\n",
        "application of pruning masks) to correctly identify the slice of the\n",
        "parameter to prune.\n",
        "\n",
        "Let's assume, for example, that you want to implement a pruning\n",
        "technique that prunes every other entry in a tensor (or -- if the\n",
        "tensor has previously been pruned -- in the remaining unpruned\n",
        "portion of the tensor). This will be of ``PRUNING_TYPE='unstructured'``\n",
        "because it acts on individual connections in a layer and not on entire\n",
        "units/channels (``'structured'``), or across different parameters\n",
        "(``'global'``).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmEx2aAGIRA9"
      },
      "source": [
        "class FooBarPruningMethod(prune.BasePruningMethod):\n",
        "    \"\"\"Prune every other entry in a tensor\n",
        "    \"\"\"\n",
        "    PRUNING_TYPE = 'unstructured'\n",
        "\n",
        "    def compute_mask(self, t, default_mask):\n",
        "        mask = default_mask.clone()\n",
        "        mask.view(-1)[::2] = 0 \n",
        "        return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTZKtPe1IRA9"
      },
      "source": [
        "Now, to apply this to a parameter in an ``nn.Module``, you should\n",
        "also provide a simple function that instantiates the method and\n",
        "applies it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvp1g-cvIRA9"
      },
      "source": [
        "def foobar_unstructured(module, name):\n",
        "    \"\"\"Prunes tensor corresponding to parameter called `name` in `module`\n",
        "    by removing every other entry in the tensors.\n",
        "    Modifies module in place (and also return the modified module) \n",
        "    by:\n",
        "    1) adding a named buffer called `name+'_mask'` corresponding to the \n",
        "    binary mask applied to the parameter `name` by the pruning method.\n",
        "    The parameter `name` is replaced by its pruned version, while the \n",
        "    original (unpruned) parameter is stored in a new parameter named \n",
        "    `name+'_orig'`.\n",
        "\n",
        "    Args:\n",
        "        module (nn.Module): module containing the tensor to prune\n",
        "        name (string): parameter name within `module` on which pruning\n",
        "                will act.\n",
        "\n",
        "    Returns:\n",
        "        module (nn.Module): modified (i.e. pruned) version of the input\n",
        "            module\n",
        "    \n",
        "    Examples:\n",
        "        >>> m = nn.Linear(3, 4)\n",
        "        >>> foobar_unstructured(m, name='bias')\n",
        "    \"\"\"\n",
        "    FooBarPruningMethod.apply(module, name)\n",
        "    return module"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucePE_zwIRA-"
      },
      "source": [
        "Let's try it out!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e546jYiQIRA-"
      },
      "source": [
        "model = Net()\n",
        "foobar_unstructured(model.fc2, name='bias')\n",
        "\n",
        "print(model.fc2.bias_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qONkUzZTRiJm",
        "outputId": "52c89184-409e-4486-ba64-b541517cf09f"
      },
      "source": [
        "new_model = model\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3150, Accuracy: 1169/10000 (12%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}